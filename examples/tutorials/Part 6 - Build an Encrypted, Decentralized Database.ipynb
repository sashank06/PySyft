{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Build an Encrypted, Decentralized Database\n",
    "\n",
    "In the last section (Part 5), we learned about the basic tools PySyft supports for encrypted computation. In this section, we're going to give one example of how to use those tools to build an encrypted, decentralized database. \n",
    "\n",
    "# Encrypted\n",
    "\n",
    "The database will be encrypted because BOTH the values in the database will be encrypted AND all queries to the database will be encrypted.\n",
    "\n",
    "# Decentralized\n",
    "\n",
    "The database will be decentralized because, using SMPC, all values will be \"shared\" amongst a variety of owners, meaning that all owners must agree to allow a query to be performed. It has no central \"owner\".\n",
    "\n",
    "# The Schema:\n",
    "\n",
    "While we could construct a variety of database types, for this first tutorial we're going to focus on a simple key-value store, where both the keys and values are strings.\n",
    "\n",
    "\n",
    "Authors:\n",
    "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook()\n",
    "\n",
    "bob = sy.VirtualWorker(id=\"bob\")\n",
    "alice = sy.VirtualWorker(id=\"alice\")\n",
    "bill = sy.VirtualWorker(id=\"bill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Constructing a Key System\n",
    "\n",
    "In this section, we're going to show how to use the equality operation to build a simple key system. The only tricky part about this is that we need to choose the datatype we want to use for keys. The most common usecase is probably strings, so that's what we're going to use here.\n",
    "\n",
    "Now, one thing you'll notice about our SMPC techniques, they all use exclusively numbers. Thus, we now have an issue. We need to decide how to encode our strings into numbers so that we can query them efficiently as \"keys\". The fastest way would be to map every possible key to a unique hash (integer) and then key based on that. Let's use that approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that sy.mpc.securenn.field is the max value that we can encode using SMPC by default\n",
    "# This is, however, somewhat configurable in the system.\n",
    "def string2key(input_str):\n",
    "    return sy.LongTensor([hash(input_str) % sy.mpc.securenn.field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 7.3583e+08\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2key(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.4739e+09\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2key(\"world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Constructing a Value Storage System\n",
    "\n",
    "Now, we are able to convert our string \"keys\" to integers which we can use for our database, but now we need to figure out how to encode the values in our database using numbers as well. For this, we're going to simply encode each string as a list of numbers like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "for i, c in enumerate(' ' + string.ascii_letters + '0123456789' + string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2values(input_str):\n",
    "    values = list()\n",
    "    for char in input_str:\n",
    "        values.append(char2int[char])\n",
    "    return sy.LongTensor(values)\n",
    "\n",
    "def values2string(input_values):\n",
    "    s = \"\"\n",
    "    for v in input_values:\n",
    "        s += int2char[int(v)]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  8\n",
       "  5\n",
       " 12\n",
       " 12\n",
       " 15\n",
       "  0\n",
       " 23\n",
       " 15\n",
       " 18\n",
       " 12\n",
       "  4\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 11]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = string2values(\"hello world\")\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2string(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Creating the Tensor Based Key-Value Store\n",
    "\n",
    "Now for our next operation, we want to write some logic which will allow us to query this database using ONLY addition, multiplication, and comparison operations. For this we will use a simple strategy. \n",
    "\n",
    "The database will be a list of integer keys and a list of integer arrays (values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list()\n",
    "values = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a value to the database, we'll just add its key and value to the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(string_key, string_value):\n",
    "    keys.append(string2key(string_key))\n",
    "    values.append(string2values(string_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry(\"Bob\",\"(123) 456-7890\")\n",
    "add_entry(\"Bill\", \"(234) 567-8901\")\n",
    "add_entry(\"Sue\",\"(345) 678-9012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  1.8915e+09\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  1.2644e+09\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  1.2281e+09\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  70\n",
       "  54\n",
       "  55\n",
       "  56\n",
       "  71\n",
       "   0\n",
       "  57\n",
       "  58\n",
       "  59\n",
       "  75\n",
       "  60\n",
       "  61\n",
       "  62\n",
       "  53\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 14], \n",
       "  70\n",
       "  55\n",
       "  56\n",
       "  57\n",
       "  71\n",
       "   0\n",
       "  58\n",
       "  59\n",
       "  60\n",
       "  75\n",
       "  61\n",
       "  62\n",
       "  53\n",
       "  54\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 14], \n",
       "  70\n",
       "  56\n",
       "  57\n",
       "  58\n",
       "  71\n",
       "   0\n",
       "  59\n",
       "  60\n",
       "  61\n",
       "  75\n",
       "  62\n",
       "  53\n",
       "  54\n",
       "  55\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 14]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Querying the Key->Value Store\n",
    "\n",
    "Our query will be in three:\n",
    "\n",
    "- 1) check for equality between the query key and every key in the database - returning a 1 or 0 for each row. We'll call each row's result it's \"key_match\" integer.\n",
    "\n",
    "- 2) Multiply each row's \"key_match\" integer by all the values in its corresponding row. This will zero out all rows in the database which don't have matching keys.\n",
    "\n",
    "- 3) Sum all the masked rows in the database together. \n",
    "\n",
    "- 4) Return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891469763"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our query\n",
    "query = \"Bob\"\n",
    "\n",
    "# convert our query to a hash\n",
    "qhash = string2key(query)\n",
    "qhash[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  1\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  0\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  0\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if our query matches any key\n",
    "key_match = list()\n",
    "for key in keys:\n",
    "    key_match.append((key == qhash).long())\n",
    "key_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply each row's value by its corresponding keymatch\n",
    "value_match = list()\n",
    "for i, value in enumerate(values):\n",
    "    value_match.append(key_match[i].expand(value.shape) * value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the values together\n",
    "final_value = value_match[0]\n",
    "for v in value_match[1:]:\n",
    "    final_value = final_value + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-7890'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decypher final value\n",
    "values2string(final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Putting It Together\n",
    "\n",
    "Here's what this logic looks like when put together in a simple database class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "\n",
    "for i, c in enumerate(' ' + string.ascii_letters + '0123456789' + string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c\n",
    "\n",
    "def string2key(input_str):\n",
    "    return sy.LongTensor([hash(input_str) % sy.mpc.securenn.field])\n",
    "\n",
    "def string2values(input_str):\n",
    "    values = list()\n",
    "    for char in input_str:\n",
    "        values.append(char2int[char])\n",
    "    return sy.LongTensor(values)\n",
    "\n",
    "def values2string(input_values):\n",
    "    s = \"\"\n",
    "    for v in input_values:\n",
    "        s += int2char[int(v)]\n",
    "    return s\n",
    "\n",
    "class TensorDB:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.keys = list()\n",
    "        self.values = list()\n",
    "        \n",
    "    def add_entry(self, string_key, string_value):\n",
    "        self.keys.append(string2key(string_key))\n",
    "        self.values.append(string2values(string_value))\n",
    "        \n",
    "    def query(self, str_query):\n",
    "        # hash the query string\n",
    "        qhash = string2key(str_query)\n",
    "        \n",
    "        # see if our query matches any key\n",
    "        key_match = list()\n",
    "        for key in self.keys:\n",
    "            key_match.append((key == qhash).long())\n",
    "\n",
    "        # Multiply each row's value by its corresponding keymatch\n",
    "        value_match = list()\n",
    "        for i,value in enumerate(self.values):\n",
    "            value_match.append(key_match[i].expand(value.shape) * value)\n",
    "            \n",
    "        # sum the values together\n",
    "        final_value = value_match[0]\n",
    "        for v in value_match[1:]:\n",
    "            final_value = final_value + v\n",
    "            \n",
    "        # Decypher final value\n",
    "        return values2string(final_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = TensorDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.add_entry(\"Bob\",\"(123) 456-7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567-8901\")\n",
    "db.add_entry(\"Sue\",\"(345) 678-9012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-7890'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(234) 567-8901'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(345) 678-9012'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Sue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Building an Encrypted, Decentralized Database\n",
    "\n",
    "Now, the interesting thing here is that we have not used a single operation other than addition, multiplication, and comparison (equality). Thus, we can trivially create an encrypted database by simply encrypting all of our keys and values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "\n",
    "for i, c in enumerate(' ' + string.ascii_letters + '0123456789' + string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c\n",
    "\n",
    "def string2key(input_str):\n",
    "    return sy.LongTensor([(hash(input_str)+1234) % int(sy.mpc.securenn.field)])\n",
    "\n",
    "def string2values(input_str):\n",
    "    values = list()\n",
    "    for char in input_str:\n",
    "        values.append(char2int[char])\n",
    "    return sy.LongTensor(values)\n",
    "\n",
    "def values2string(input_values):\n",
    "    s = \"\"\n",
    "    for v in input_values:\n",
    "        if(int(v) in int2char):\n",
    "            s += int2char[int(v)]\n",
    "        else:\n",
    "            s += \".\"\n",
    "    return s\n",
    "\n",
    "\n",
    "class DecentralizedDB:\n",
    "    \n",
    "    def __init__(self, *owners):\n",
    "        self.owners = owners\n",
    "        self.keys = list()\n",
    "        self.values = list()\n",
    "        \n",
    "    def add_entry(self, string_key, string_value):\n",
    "        key = string2key(string_key).share(*self.owners)\n",
    "        value = string2values(string_value).share(*self.owners)\n",
    "        \n",
    "        self.keys.append(key)\n",
    "        self.values.append(value)\n",
    "        \n",
    "    def query(self, str_query):\n",
    "        # hash the query string\n",
    "        qhash = sy.LongTensor([string2key(str_query)])\n",
    "        qhash = qhash.share(*self.owners)\n",
    "        \n",
    "        # see if our query matches any key\n",
    "        key_match = list()\n",
    "        for key in self.keys:\n",
    "            key_match.append((key == qhash))\n",
    "\n",
    "        # Multiply each row's value by its corresponding keymatch\n",
    "        value_match = list()\n",
    "        for i, value in enumerate(self.values):\n",
    "            shape = list(value.get_shape())\n",
    "            km = key_match[i]\n",
    "            expanded_key = km.expand(1,shape[0])[0]\n",
    "            value_match.append(expanded_key * value)\n",
    "            \n",
    "        # sum the values together\n",
    "        final_value = value_match[0]\n",
    "        for v in value_match[1:]:\n",
    "            final_value = final_value + v\n",
    "        \n",
    "        result = values2string(final_value.get())\n",
    "        \n",
    "        # there is a certain element of randomness\n",
    "        # which can cause the database to return empty\n",
    "        # so if this happens, just try again\n",
    "        if(list(set(result))[0] == '.'):\n",
    "            return self.query(str_query)\n",
    "            \n",
    "        # Decypher final value\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DecentralizedDB(bob, alice)\n",
    "db.add_entry(\"Bob\",\"(123) 456-7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567-8901\")\n",
    "db.add_entry(\"Sam\",\"(345) 678-9012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..... ........'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(234) 567-8901'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(345) 678-9012'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Sam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!!!\n",
    "\n",
    "And there you have it! We now have a key-value store capable of storing arbitrary strings and values in an encrypted, decentralized state such that even the queries are also private/encrypted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Increasing Performance\n",
    "\n",
    "\n",
    "### Strategy 1: One-hot Encoded Keys\n",
    "\n",
    "As it turns out, comparisons (like ==) can be very expensive to compute, which make the query take a long time. Thus, we also have another option. We can encode our strings using one_hot encodings. This allows us to exclusively use multiplication for our database query, like so.\n",
    "\n",
    "### Strategy 2: Fixed Length Values\n",
    "By using fixed length values, we can encode the whole database as a single tensor which lets us use the underlying hardware to work a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "\n",
    "for i, c in enumerate(' ' + string.ascii_lowercase + '0123456789' + string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c\n",
    "\n",
    "def one_hot(index, length):\n",
    "    vect = sy.zeros(length).long()\n",
    "    vect[index]  = 1\n",
    "    return vect\n",
    "    \n",
    "def string2one_hot_matrix(str_input, max_len=8):\n",
    "    # truncate strings longer than max_len\n",
    "    str_input = str_input[:max_len].lower()\n",
    "    \n",
    "    # pad strings shorter than max_len\n",
    "    if(len(str_input) < max_len):\n",
    "        str_input = str_input + \".\" * (max_len - len(str_input))\n",
    "    \n",
    "    char_vectors = list()\n",
    "    for char in str_input:\n",
    "        char_vectors.append(one_hot(char2int[char],len(int2char)).unsqueeze(0))\n",
    "    \n",
    "    return sy.cat(char_vectors,dim=0)\n",
    "\n",
    "def string2values(str_input, max_len=128):\n",
    "    # truncate strings longer than max_len\n",
    "    str_input = str_input[:max_len].lower()\n",
    "    \n",
    "    # pad strings shorter than max_len\n",
    "    if(len(str_input) < max_len):\n",
    "        str_input = str_input + \".\" * (max_len - len(str_input))\n",
    "    \n",
    "    \n",
    "    values = list()\n",
    "    for char in str_input:\n",
    "        values.append(char2int[char])\n",
    "        \n",
    "    return sy.LongTensor(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hots = string2one_hot_matrix(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentralizedDB:\n",
    "    \n",
    "    def __init__(self, *owners, max_key_len=8, max_value_len=256):\n",
    "        self.max_key_len = max_key_len\n",
    "        self.max_value_len = max_value_len\n",
    "        self.owners = owners\n",
    "        self.keys = list()\n",
    "        self.values = list()\n",
    "        \n",
    "    def add_entry(self, string_key, string_value):\n",
    "        key = string2one_hot_matrix(string_key, self.max_key_len).share(*self.owners)\n",
    "        value = string2values(string_value, self.max_value_len).share(*self.owners)\n",
    "        \n",
    "        self.keys.append(key)\n",
    "        self.values.append(value)\n",
    "        \n",
    "    def query(self,query_str):\n",
    "        query = string2one_hot_matrix(query_str, self.max_key_len).send(*self.owners)\n",
    "        \n",
    "        # see if our query matches any key\n",
    "        # note: this is the slowest part of the program\n",
    "        # it could probably be greatly faster with minimal improvements\n",
    "        key_match = list()\n",
    "        for key in self.keys:\n",
    "            vect = (key * query).sum(1)\n",
    "            x = vect[0]\n",
    "            for i in range(vect.get_shape()[0]):\n",
    "                x = x * vect[i]\n",
    "            key_match.append(x)\n",
    "\n",
    "        # Multiply each row's value by its corresponding keymatch\n",
    "        value_match = list()\n",
    "        for i, value in enumerate(self.values):\n",
    "            shape = list(value.get_shape())\n",
    "            km = key_match[i]\n",
    "            expanded_key = km.expand(1,shape[0])[0]\n",
    "            value_match.append(expanded_key * value)\n",
    "\n",
    "        # NOTE: everything before this line could (in theory) happen in full parallel\n",
    "        # on different threads.\n",
    "            \n",
    "        # sum the values together\n",
    "        final_value = value_match[0]\n",
    "        for v in value_match[1:]:\n",
    "            final_value = final_value + v\n",
    "\n",
    "        result = values2string(final_value.get())\n",
    "        \n",
    "        return result.replace(\".\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "db  = DecentralizedDB(bob, alice, bill, max_key_len=3)\n",
    "db.add_entry(\"Bob\",\"(123) 456 7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567 8901\")\n",
    "db.add_entry(\"Sam\",\"(345) 678 9012\")\n",
    "db.add_entry(\"Key\",\"really big json value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456 7890'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(234) 567 8901'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(345) 678 9012'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                '"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Not a Person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'really big json value'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!!\n",
    "\n",
    "And there we have it - a marginally more performant version. We could further add performance by running the query on all the rows in parallel, but we'll leave that for someone else to work on :).\n",
    "\n",
    "\n",
    "Note: we can add as many owners to the database as we want! (although the more owners you have the slower queries will be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker alice already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker bill already exists. Replacing old worker which could cause unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook()\n",
    "\n",
    "bob = sy.VirtualWorker(id=\"bob\")\n",
    "alice = sy.VirtualWorker(id=\"alice\")\n",
    "bill = sy.VirtualWorker(id=\"bill\")\n",
    "sue = sy.VirtualWorker(id=\"sue\")\n",
    "tara = sy.VirtualWorker(id=\"tara\")\n",
    "\n",
    "db  = DecentralizedDB(bob, alice, bill, sue, tara, max_key_len=3)\n",
    "db.add_entry(\"Bob\",\"(123) 456 7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567 8901\")\n",
    "db.add_entry(\"Sam\",\"(345) 678 9012\")\n",
    "db.add_entry(\"Key\",\"really big json value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456 7890'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congraulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on Github\n",
    "\n",
    "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft Github Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for github issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
