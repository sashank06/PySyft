{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning with Diff Privacy using PySyft\n",
    "# Client Side\n",
    "\n",
    "When effectively implementing Federated Learning in real world applications, it is important to build an architeture where data in a remote server could be accessed in order to train and test the model. \n",
    "\n",
    "In the previous examples this is implemented using virtual clients. This example attempts to implement it over websockets.\n",
    "\n",
    "This notebook is the client side where the model is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! URL=\"https://github.com/LaRiffle/differential-privacy.git\" && FOLDER=\"differential_privacy\" && if [ ! -d $FOLDER ]; then git clone $URL $FOLDER; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
    "! pip install --upgrade --force-reinstall websockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "hook = sy.TorchHook(local_worker=sy.SocketWorker(id=0, port=3001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_client = sy.SocketWorker(hook=hook,id=3, port=3000, is_pointer=True)\n",
    "hook.local_worker.add_worker(remote_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc3 = nn.Linear(24, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    #New method\n",
    "    def divide_clip_grads(self):\n",
    "        for key, param in self.named_parameters():\n",
    "            param.grad /= n_batch\n",
    "            gradient_clip(param)\n",
    "    \n",
    "    #New method\n",
    "    def add_noise_to_grads(self):\n",
    "        for key, param in self.named_parameters():\n",
    "            noise = 1/LOT_SIZE * gaussian_noise(param.grad)\n",
    "            param.grad += noise\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# |\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differencial Privacy model\n",
    "\n",
    "This part to implement differentaial privacy is directly taken from the 'Boston_Housing_Federated_Training with Secure Aggregation and Diff Privacy' example.\n",
    "\n",
    "The 'lot' is a batch defined in that example for aggregation. At the moment this is directly applied with integer inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from differential_privacy.privacy_accountant.pytorch import accountant\n",
    "\n",
    "n_batch = 3\n",
    "NUM_TRAINING_IMAGES = 404\n",
    "LOT_SIZE = n_batch * 8\n",
    "N_LOTS = 100\n",
    "T = N_LOTS # number of samplings\n",
    "\n",
    "bound = 10\n",
    "epsilon = 0.5\n",
    "delta = 10**(-5)\n",
    "sigma = np.sqrt(2 * np.log(1.25/delta))/epsilon \n",
    "\n",
    "def sum_batch(grads):\n",
    "    n_items = len(grads)\n",
    "    return grads.view(n_items, -1).sum(dim=1)\n",
    "\n",
    "def gradient_clip(param):\n",
    "    \"\"\"Clip gradient to ensure ||param.grad||2 < bound\"\"\"\n",
    "    nn.utils.clip_grad_norm([param], bound)\n",
    "\n",
    "def gaussian_noise(grads):\n",
    "    \"\"\"Add gaussian noise to gradients\"\"\"\n",
    "    shape = grads.shape\n",
    "    noise = Variable(torch.zeros(shape))\n",
    "    noise.data.normal_(0.0, std=bound*sigma)\n",
    "    return noise\n",
    "\n",
    "q = LOT_SIZE / NUM_TRAINING_IMAGES\n",
    "spent_epsilon = q * epsilon * np.sqrt(T)\n",
    "spent_delta = delta\n",
    "print('sigma =', sigma)\n",
    "print('The mechanism is (O(%f), %f)-differentially private' % (spent_epsilon, spent_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_accountant = accountant.GaussianMomentsAccountant(NUM_TRAINING_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set = remote_client.search([\"#X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = remote_client.search([\"#y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, target):\n",
    "    model.train()\n",
    "    \n",
    "#     data = sy.Var(data)\n",
    "#     target = sy.Var(target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    model.send(remote_client)\n",
    "           \n",
    "    # update the model\n",
    "    pred = model(data)\n",
    "    loss = F.mse_loss(pred, target.float())\n",
    "    # Note that because we apply backward() several times without resetting \n",
    "    # the grads (optimizer.zero_grad()), we sum the gradients \n",
    "    loss.backward()\n",
    "\n",
    "#         print(loss)\n",
    "    print(loss.get())\n",
    "\n",
    "       \n",
    "\n",
    "    model.get() # <-- We should call get after add_noise_to_grads, but for simplicity we called it before.\n",
    "          \n",
    "    model.divide_clip_grads()\n",
    "   \n",
    "    model.add_noise_to_grads()\n",
    "    \n",
    "#     model.get()\n",
    "    \n",
    "    optimizer.step()\n",
    "        \n",
    "    priv_accountant.accumulate_privacy_spending(bound * sigma, LOT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_set)):\n",
    "    train(X_set[i], y_set[i])\n",
    "\n",
    "# train(X_set, y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
